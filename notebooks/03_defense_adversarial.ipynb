{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b230e62d",
   "metadata": {},
   "source": [
    "# Adversarial Training Defense for EuroSAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6a840",
   "metadata": {},
   "source": [
    "### 1. Setup environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30976eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.defense.data_augmentation import get_dataloaders\n",
    "from src.attacks.utils import extract_mean_std\n",
    "from src.training.evaluate import evaluate_model\n",
    "from src.attacks.pgd import pgd_attack_batch\n",
    "from src.attacks.metrics_eval import evaluate_adv, plot_confusion_matrix  \n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PGDConfig:\n",
    "    eps: float = 0.005\n",
    "    alpha: Optional[float] = None   \n",
    "    iters: int = 50\n",
    "    small_step_fraction: float = 0.2\n",
    "    grad_mask_fraction: float = 0.25\n",
    "    grad_blur_sigma: float = 1.0\n",
    "    smooth_perturb_sigma: float = 1.0\n",
    "    random_dither: bool = True\n",
    "    dither_scale: float = 0.5\n",
    "    device: Optional[torch.device] = None\n",
    "\n",
    "\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ðŸš€ Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c77d994",
   "metadata": {},
   "source": [
    "### 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"resnet50\"\n",
    "data_dir = \"../data/raw\"\n",
    "checkpoint_dir = \"../experiments/checkpoints\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_e2.pth\")\n",
    "adv_checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}_adv3.pth\")\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 5e-5\n",
    "blur=2.0\n",
    "# eps = 2/255 \n",
    "# alpha = eps / 10\n",
    "# pgd_steps = 40\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f763f6cf",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929af6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, val_loader, test_loader, classes = get_dataloaders(\n",
    "    data_dir=data_dir, batch_size=batch_size\n",
    ")\n",
    "num_classes = len(classes)\n",
    "print(f\"âœ… Loaded {num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e33280",
   "metadata": {},
   "source": [
    "### 4. Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name.lower() == \"resnet50\":\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name.lower() == \"resnet18\":\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model_name: {model_name}\")\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"ðŸ“¦ Loaded pretrained weights from {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df68d2",
   "metadata": {},
   "source": [
    "### 5. Adversarial Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversarial(\n",
    "    model,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=30,\n",
    "    grad_mask_fraction=0.25,\n",
    "    smooth_sigma=1.0,\n",
    "    dither_scale=0.3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Adversarial Training with CAT (Curriculum Adversarial Training)\n",
    "    \"\"\"\n",
    "\n",
    "    mean_t, std_t = extract_mean_std(train_loader)\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ======================================================\n",
    "        # ðŸ”¥ Curriculum Adversarial Training schedule (CAT)\n",
    "        # ======================================================\n",
    "        if epoch < 5:\n",
    "            # ------------------------ Stage 1 ------------------------\n",
    "            eps = 1/255\n",
    "            iters = int(5 + (epoch / 5) * 5)     # 5 â†’ 10\n",
    "            alpha = eps / 4\n",
    "            blur=2.0\n",
    "\n",
    "        elif epoch < 15:\n",
    "            # ------------------------ Stage 2 ------------------------\n",
    "            eps = 4/255\n",
    "            iters = int(20 + ((epoch-5) / 10) * 10)  # 20 â†’ 30\n",
    "            alpha = eps / 6\n",
    "            blur=1.0\n",
    "\n",
    "        else:\n",
    "            # ------------------------ Stage 3 ------------------------\n",
    "            eps = 8/255\n",
    "            iters = int(40 + ((epoch-15) / 15) * 10)  # 40 â†’ 50\n",
    "            alpha = eps / 10\n",
    "            blur=0.5\n",
    "\n",
    "        # Build PGD config\n",
    "        pgd_conf = PGDConfig(\n",
    "            eps=eps,\n",
    "            alpha=alpha,\n",
    "            iters=iters,\n",
    "            grad_mask_fraction=grad_mask_fraction,\n",
    "            grad_blur_sigma=blur,\n",
    "            smooth_perturb_sigma=smooth_sigma,\n",
    "            random_dither=True,\n",
    "            dither_scale=dither_scale,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"\\nðŸŽ¯ Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"PGD iters={pgd_conf.iters}  eps={pgd_conf.eps:.5f}  alpha={pgd_conf.alpha:.5f}\"\n",
    "        )\n",
    "\n",
    "        # ======================================================\n",
    "        # Training Epoch\n",
    "        # ======================================================\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total, correct = 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Training\", leave=False)\n",
    "\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # ---- Generate adversarial examples ----\n",
    "            adv_images = pgd_attack_batch(\n",
    "                model=model,\n",
    "                images=images,\n",
    "                labels=labels,\n",
    "                config=pgd_conf,\n",
    "                targeted=False\n",
    "            )\n",
    "\n",
    "            # ---- Combine clean + adversarial images ----\n",
    "            combined_images = torch.cat([images, adv_images], dim=0)\n",
    "            combined_labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(combined_images)\n",
    "            loss = criterion(outputs, combined_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == combined_labels).sum().item()\n",
    "            total += combined_labels.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "            f\"| Loss: {running_loss/len(train_loader):.4f} \"\n",
    "            f\"| Clean+Adv Acc: {100 * correct/total:.2f}%\"\n",
    "        )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf425d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ§  Starting Adversarial Training...\")\n",
    "\n",
    "adv_model = train_adversarial(\n",
    "    model,\n",
    "    train_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device=device,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "torch.save(adv_model.state_dict(), adv_checkpoint_path)\n",
    "print(f\"\\nâœ… Adversarially trained model saved at: {adv_checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f1a15",
   "metadata": {},
   "source": [
    "### 6. Evaluate on Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Evaluating on clean test set...\")\n",
    "metrics_clean = evaluate_model(\n",
    "    model_path=adv_checkpoint_path,\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Test Set Performance:\")\n",
    "print(f\"Num images: {metrics_clean['num_images']}\")\n",
    "print(f\"Accuracy:  {metrics_clean['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss:      {metrics_clean['loss']:.4f}\")\n",
    "print(f\"Precision: {metrics_clean['precision']:.4f}\")\n",
    "print(f\"Recall:    {metrics_clean['recall']:.4f}\")\n",
    "print(f\"F1-score:  {metrics_clean['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ” Classification metrics per class:\\n\")\n",
    "print(metrics_clean[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(metrics_clean['confusion_matrix'], metrics_clean['class_names'], normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5895724",
   "metadata": {},
   "source": [
    "### 7. Evaluate on Adversarial Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš”ï¸ Evaluating on PGD adversarial test set...\")\n",
    "adv_dir = '../data/adv/adv_2'\n",
    "\n",
    "res_eval = evaluate_adv(\n",
    "    model_path=adv_checkpoint_path,\n",
    "    adv_folder=adv_dir,\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    mean_std_sample_size=2000,\n",
    "    image_pattern=\"*.tif\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Test Set Performance:\")\n",
    "print(f\"Num images: {res_eval['num_images']}\")\n",
    "print(f\"Accuracy: {res_eval['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss: {res_eval['loss']:.4f}\")\n",
    "print(f\"Precision: {res_eval['precision']:.4f}\")\n",
    "print(f\"Recall: {res_eval['recall']:.4f}\")\n",
    "print(f\"F1-score: {res_eval['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification metrics per category:\\n\\n\", res_eval[\"classification_report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d63b45",
   "metadata": {},
   "source": [
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72baaf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(res_eval['confusion_matrix'], res_eval['class_names'], normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
