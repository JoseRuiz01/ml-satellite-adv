{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef115af",
   "metadata": {},
   "source": [
    "# PGD attacks\n",
    "\n",
    "This notebook tests **EuroSAT ResNet18 model** on images modified with **PGD attacks**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d9f70",
   "metadata": {},
   "source": [
    "### 1. Setup environment and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d449ca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "if not hasattr(sys, \"frozen\"):\n",
    "    os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from skimage.transform import resize\n",
    "\n",
    "from src.training.simple_cnn import SimpleCNN\n",
    "from src.data.dataloader import get_dataloaders\n",
    "from src.attacks.evaluate import evaluate_pgd             \n",
    "from src.attacks.metrics_eval import evaluate_adv, plot_confusion_matrix  \n",
    "from src.attacks.utils import select_rgb_bands, gdal_style_scale\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"resnet50\" # or resnet18 simplecnn\n",
    "data_dir = '../data/raw'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e182d54",
   "metadata": {},
   "source": [
    "- Get path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4903627",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"simplecnn\":\n",
    "        checkpoint_path = \"../experiments/checkpoints/simplecnn_best.pth\"\n",
    "elif model_name == \"resnet18\":\n",
    "        checkpoint_path = \"../experiments/checkpoints/resnet18_best.pth\"\n",
    "elif model_name == \"resnet50\":\n",
    "        checkpoint_path = \"../experiments/checkpoints/resnet50_e2.pth\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f49e1",
   "metadata": {},
   "source": [
    "### 2. Load data and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b611e",
   "metadata": {},
   "source": [
    "- Load dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d388079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 classes: ['AnnualCrop', 'Forest', 'Residential', 'River']\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, classes = get_dataloaders(data_dir=data_dir, batch_size=batch_size)\n",
    "print(f'Loaded {len(classes)} classes: {classes}')\n",
    "\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac97b7d",
   "metadata": {},
   "source": [
    "- Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b269473",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name.lower() == \"resnet18\":\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name.lower() == \"resnet50\":\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "elif model_name.lower() == \"simplecnn\":\n",
    "    model = SimpleCNN(num_classes=num_classes)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported model_name: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2e04b4",
   "metadata": {},
   "source": [
    "- Load trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c6e8601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a616a35",
   "metadata": {},
   "source": [
    "### 3. Run PGD attacks and save adversarial images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d71445b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joseantonioruizheredia/Code/Python/ml-satellite-adv/src/attacks/utils.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mean = torch.tensor(t.mean).view(-1, 1, 1)\n",
      "/Users/joseantonioruizheredia/Code/Python/ml-satellite-adv/src/attacks/utils.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  std = torch.tensor(t.std).view(-1, 1, 1)\n",
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD run result: {'clean_acc': 0.998840579710145, 'adv_acc': 0.991304347826087, 'clean_loss': 0.005903373479951119, 'adv_loss': 0.021152364750919136, 'eps': 0.005, 'saved': 0, 'out_dir': '/Users/joseantonioruizheredia/Code/Python/ml-satellite-adv/data/pgd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "out_dir = '../data/pgd'\n",
    "\n",
    "eps = 0.005\n",
    "alpha = eps / 10\n",
    "iters = 200\n",
    "\n",
    "res = evaluate_pgd(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    device=device,\n",
    "    eps=eps,\n",
    "    alpha=alpha,\n",
    "    iters=iters,\n",
    "    out_dir=out_dir,\n",
    "    save_every=40,\n",
    "    max_save=64,\n",
    "    targeted=False,\n",
    "    target_class=None\n",
    ")\n",
    "\n",
    "print('PGD run result:', res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c941db19",
   "metadata": {},
   "source": [
    "### 4. Evaluate saved adversarial images for each epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6ad9f",
   "metadata": {},
   "source": [
    "- Evaluation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d59f2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model Evaluation on Adversarial Images ===\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No images matching *.tif found in ../data/pgd",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Model Evaluation on Adversarial Images ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m metrics_adv = \u001b[43mevaluate_adv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43madv_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmean_std_sample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_pattern\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*.tif\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNum images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_adv[\u001b[33m'\u001b[39m\u001b[33mnum_images\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics_adv[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/src/attacks/metrics_eval.py:154\u001b[39m, in \u001b[36mevaluate_adv\u001b[39m\u001b[34m(adv_folder, model_path, data_dir, batch_size, model_name, device, mean_std_sample_size, image_pattern)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    152\u001b[39m         class_names = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m adv_ds = \u001b[43mAdvFolderDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m adv_loader = DataLoader(adv_ds, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers=\u001b[32m2\u001b[39m)\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/Python/ml-satellite-adv/src/attacks/metrics_eval.py:39\u001b[39m, in \u001b[36mAdvFolderDataset.__init__\u001b[39m\u001b[34m(self, folder, transform, pattern, class_names, data_dir)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mself\u001b[39m.filepaths = \u001b[38;5;28msorted\u001b[39m(glob.glob(os.path.join(folder, pattern)))\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.filepaths) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images matching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m.class_names = class_names\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.class_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m data_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_dataloaders \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: No images matching *.tif found in ../data/pgd"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== Model Evaluation on Adversarial Images ===\")\n",
    "\n",
    "metrics_adv = evaluate_adv(\n",
    "    adv_folder=out_dir,\n",
    "    model_path=checkpoint_path,\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    device=device,\n",
    "    mean_std_sample_size=2000,\n",
    "    image_pattern=\"*.tif\"\n",
    ")\n",
    "\n",
    "print(f\"Num images: {metrics_adv['num_images']}\")\n",
    "\n",
    "print(f\"Accuracy: {metrics_adv['accuracy']*100:.2f}%\")\n",
    "print(f\"Loss: {metrics_adv['loss']:.4f}\")\n",
    "print(f\"Precision: {metrics_adv['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics_adv['recall']:.4f}\")\n",
    "print(f\"F1-score: {metrics_adv['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification metrics per category:\\n\\n\", metrics_adv[\"classification_report\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa240e1",
   "metadata": {},
   "source": [
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(metrics_adv['confusion_matrix'], metrics_adv['class_names'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f19d1",
   "metadata": {},
   "source": [
    "- Show a small sample of images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_folder = '../data/pgd'\n",
    "raw_folder = '../data/raw'\n",
    "adv_paths = sorted(glob.glob(os.path.join(adv_folder, \"*.tif\")))\n",
    "\n",
    "pairs = []\n",
    "for adv_p in adv_paths:\n",
    "    base = os.path.basename(adv_p)\n",
    "    orig_base = re.sub(r\"_true\\d+_pred\\d+\\.tif$\", \".tif\", base)\n",
    "    orig_candidates = glob.glob(os.path.join(raw_folder, \"**\", orig_base), recursive=True)\n",
    "    if not orig_candidates:\n",
    "        continue\n",
    "    pairs.append((adv_p, orig_candidates[0]))\n",
    "\n",
    "if len(pairs) == 0:\n",
    "    print(\"No matching pairs found.\")\n",
    "else:\n",
    "    random.shuffle(pairs)\n",
    "    pairs = pairs[:10]\n",
    "    fig, axs = plt.subplots(len(pairs), 3, figsize=(12, 4 * len(pairs)), dpi=400)\n",
    "    axs = np.atleast_2d(axs)\n",
    "\n",
    "    for i, (adv_p, orig_p) in enumerate(pairs):\n",
    "        adv = tifffile.imread(adv_p)\n",
    "        orig = tifffile.imread(orig_p)\n",
    "        raw_diff = np.abs(adv.astype(np.float32) - orig.astype(np.float32))\n",
    "\n",
    "        if adv.ndim == 3 and adv.shape[0] in [3,4,13]:\n",
    "            adv = np.transpose(adv, (1,2,0))\n",
    "        if orig.ndim == 3 and orig.shape[0] in [3,4,13]:\n",
    "            orig = np.transpose(orig, (1,2,0))\n",
    "\n",
    "        adv_rgb = select_rgb_bands(adv)\n",
    "        orig_rgb = select_rgb_bands(orig)\n",
    "        if adv_rgb.shape != orig_rgb.shape:\n",
    "            orig_rgb = resize(orig_rgb, adv_rgb.shape, preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "        adv_disp = gdal_style_scale(adv_rgb)\n",
    "        orig_disp = gdal_style_scale(orig_rgb)\n",
    "\n",
    "        class_name = os.path.basename(os.path.dirname(orig_p))\n",
    "\n",
    "        ax0, ax1, ax2 = axs[i]\n",
    "        \n",
    "        # Original image\n",
    "        ax0.imshow(orig_disp)\n",
    "        ax0.set_title(f\"Original (normalized)\\nClass: {class_name}\", fontsize=9)\n",
    "        ax0.axis(\"off\")\n",
    "        \n",
    "        # Adversarial image\n",
    "        ax1.imshow(adv_disp)\n",
    "        ax1.set_title(f\"Adversarial (normalized)\\nClass: {class_name}\", fontsize=9)\n",
    "        ax1.axis(\"off\")\n",
    "\n",
    "        # Difference heatmap\n",
    "        diff = np.mean(np.abs(adv_disp - orig_disp), axis=2)\n",
    "        p99 = np.percentile(diff, 90)\n",
    "        diff_clipped = np.clip(diff / (p99 + 1e-12), 0, 10)\n",
    "        gamma = 0.5  \n",
    "        diff_vis = diff_clipped ** gamma\n",
    "        \n",
    "        im = ax2.imshow(diff_vis, cmap='hot_r', interpolation='nearest')\n",
    "        m_true = re.search(r\"_true(\\d+)\", adv_p)\n",
    "        m_pred = re.search(r\"_pred(\\d+)\", adv_p)\n",
    "        true_label = m_true.group(1) if m_true else \"?\"\n",
    "        pred_label = m_pred.group(1) if m_pred else \"?\"\n",
    "\n",
    "        ax2.set_title(f\"Diff heatmap\\nTrue: {true_label}, Pred: {pred_label}\", fontsize=9)\n",
    "        ax2.axis(\"off\")\n",
    "\n",
    "        ax2.text(\n",
    "            0.9, 0.1,\n",
    "            f\"Normalize diff: {diff.mean():.4f}\\nRaw diff: {raw_diff.mean():.4f}\",\n",
    "            color='white',\n",
    "            fontsize=9,\n",
    "            ha='right',\n",
    "            va='bottom',\n",
    "            transform=ax2.transAxes,\n",
    "            bbox=dict(facecolor='black', alpha=0.8, pad=2)\n",
    "        )\n",
    "\n",
    "        cbar = fig.colorbar(im, ax=ax2, fraction=0.046, pad=0.02)\n",
    "        cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
